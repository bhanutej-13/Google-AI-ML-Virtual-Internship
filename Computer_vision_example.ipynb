{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Computer Vision Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels associated with the dataset are:\n",
    "\n",
    "0 = T-shirt/top                                                                                              \n",
    "1 = Trouser                                                                                          \n",
    "2 = Pullover                                                                                                                             \n",
    "3 = Dress                                                            \n",
    "4 = Coat                            \n",
    "5 = Sandal                                   \n",
    "6 = Shirt                                                                      \n",
    "7 = Sneaker                                  \n",
    "8 = Bag                                                       \n",
    "9 = Ankle boot                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do those values look like? Print a training image and a training label to see. You can experiment with different indices in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does these values look like? Let's print a training image, and a training label to see...Experiment with different indices in the array. For example, also take a look at index 42...that's a a different boot than the one at index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
      "  180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
      "  169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
      "  198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
      "  232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
      "  222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
      "  211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
      "  224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
      "  255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
      "  168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
      "  239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
      "  199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
      "  195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
      "  210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
      "  182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample image and label\n",
    "plt.imshow(training_images[0], cmap='gray')\n",
    "plt.title(f\"Label: {training_labels[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that all the values are integers between 0 and 255. When training a neural network, it's easier to treat all values as between 0 and 1, a process called normalization. Fortunately, Python provides an easy way to normalize a list like that without looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the Model Design\n",
    "- Flatten Layer: Converts multi-dimensional input (e.g., images) into a 1D vector for processing.\n",
    "- Dense Layer (128, ReLU): Fully connected layer with 128 neurons using ReLU activation to introduce non-linearity.\n",
    "- Dense Layer (10, Softmax): Outputs class probabilities for 10 categories using the softmax function for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile and Train the Model\n",
    "After defining the model, you need to compile it using an optimizer, a loss function, and evaluation metrics. This prepares the model for training.\n",
    "\n",
    "- Compiling the Model                        \n",
    "Optimizer (Adam): Adjusts the model weights to minimize the loss function.                               \n",
    "Loss (sparse_categorical_crossentropy): Suitable for multi-class classification with integer labels.                               \n",
    "Metrics (accuracy): Measures the proportion of correct predictions.                              \n",
    "                     \n",
    "- Training the Model                        \n",
    "model.fit(training_images, training_labels, epochs=5)                            \n",
    "training_images: Input data for the model.                               \n",
    "training_labels: Correct labels corresponding to the training data.                                  \n",
    "epochs=5: Number of times the model sees the entire dataset during training.                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.6308\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8595 - loss: 0.3809\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.3396\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8830 - loss: 0.3193\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8906 - loss: 0.2921\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Model\n",
    "\n",
    "test_images: Input data the model hasn't seen during training.\n",
    "test_labels: Correct labels corresponding to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8671 - loss: 0.3766\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3762980103492737 0.866599977016449\n"
     ]
    }
   ],
   "source": [
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploration exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "[1.1359828e-06 3.0130469e-09 3.4753477e-08 4.6517620e-08 4.4007997e-08\n",
      " 5.4977280e-03 1.5456554e-06 4.5273349e-02 2.6738699e-06 9.4922352e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7791 - loss: 0.6210\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.8628 - loss: 0.3814\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8764 - loss: 0.3381\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8848 - loss: 0.3124\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8932 - loss: 0.2880\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8662 - loss: 0.3681\n",
      "\n",
      "Neurons: 128\n",
      "Training Time: 93.2s\n",
      "Test Accuracy: 0.865\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f\"\\nNeurons: {128}\")\n",
    "print(f\"Training Time: {training_time:.1f}s\")\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 14ms/step - accuracy: 0.7952 - loss: 0.5852\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.8663 - loss: 0.3659\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.8827 - loss: 0.3214\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.8866 - loss: 0.3021\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8960 - loss: 0.2793\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8778 - loss: 0.3512\n",
      "\n",
      "Neurons: 512\n",
      "Training Time: 130.4s\n",
      "Test Accuracy: 0.879\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f\"\\nNeurons: {512}\")\n",
    "print(f\"Training Time: {training_time:.1f}s\")\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1024 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - accuracy: 0.7918 - loss: 0.5815\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.8649 - loss: 0.3654\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8825 - loss: 0.3202\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.2948\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8969 - loss: 0.2765\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.3947\n",
      "\n",
      "Neurons: 1024\n",
      "Training Time: 119.6s\n",
      "Test Accuracy: 0.862\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f\"\\nNeurons: {1024}\")\n",
    "print(f\"Training Time: {training_time:.1f}s\")\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(32,), output.shape=(32, 28, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu),\n\u001b[0;32m     18\u001b[0m                                     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax)])\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m     28\u001b[0m classifications \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_images)\n",
      "File \u001b[1;32mc:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:725\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m     )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    726\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must have rank (ndim) `target.ndim - 1`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(32,), output.shape=(32, 28, 10)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "#                                     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                     tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Temp\\ipykernel_26484\\1013696507.py\", line 24, in <module>\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 371, in fit\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 219, in function\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 113, in one_step_on_data\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 60, in train_step\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 383, in _compute_loss\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 351, in compute_loss\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 691, in __call__\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 700, in call\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 67, in __call__\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 33, in call\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1963, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 9 which is outside the valid range of [0, 5).  Label values: 7 2 1 3 4 0 2 5 6 0 9 5 6 0 7 0 7 9 9 4 4 3 4 7 9 8 6 0 1 8 6 0\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_808537]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     18\u001b[0m                                     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu),\n\u001b[0;32m     19\u001b[0m                                     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax)])\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m     28\u001b[0m classifications \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_images)\n",
      "File \u001b[1;32mc:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Temp\\ipykernel_26484\\1013696507.py\", line 24, in <module>\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 371, in fit\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 219, in function\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 113, in one_step_on_data\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 60, in train_step\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 383, in _compute_loss\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 351, in compute_loss\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 691, in __call__\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 700, in call\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 67, in __call__\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 33, in call\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1963, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\Pailla Bhanu Tej\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 9 which is outside the valid range of [0, 5).  Label values: 7 2 1 3 4 0 2 5 6 0 9 5 6 0 7 0 7 9 9 4 4 3 4 7 9 8 6 0 1 8 6 0\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_808537]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "#                                     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                     tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# Replace the above model definiton with this one to see the network with 5 output layers\n",
    "# And you'll see errors as a result!\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
